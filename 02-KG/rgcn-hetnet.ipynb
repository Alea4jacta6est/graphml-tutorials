{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-relational Link Prediction on Knowledge Graphs\n",
    "By Haoxin Li, on 13 July 2020\n",
    "\n",
    "In the biological world, different types of relation could exist between two entities. For example, a drug/chemical compound can act as a *target, enzyme, carrier* or *transporter* on proteins, forming 4 types of edges. Thus, it would not be ideal to represent these relations using the same edge embeddings. In this demo, we explore [Relational Graph Convolutional Neural Network](https://arxiv.org/pdf/1703.06103.pdf) (RGCN) and apply this achitecture on real world biological dataset, including protein-protein interactions, and drug-protein interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, GraphSAINTRandomWalkSampler, NeighborSampler, GraphSAINTEdgeSampler\n",
    "from torch_geometric.nn import RGCNConv, Node2Vec, FastRGCNConv\n",
    "from torch_geometric.utils import negative_sampling, contains_isolated_nodes\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, f1_score, average_precision_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_attr=[1515256], edge_index=[2, 1515256], edge_type=[1515256, 1], test_mask=[1515256], train_mask=[1515256], val_mask=[1515256], x=[25455, 128], y=[25455])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index = torch.load('data/edge_index.pt')\n",
    "edge_attr = torch.load('data/edge_attr.pt')\n",
    "edge_type = torch.load('data/edge_type.pt')\n",
    "x = torch.load('data/x.pt')\n",
    "y = torch.load('data/y.pt')\n",
    "\n",
    "train_mask = torch.load('data/train_mask.pt')\n",
    "val_mask = torch.load('data/val_mask.pt')\n",
    "test_mask = torch.load('data/test_mask.pt')\n",
    "\n",
    "num_relations = edge_type.unique().size(0)\n",
    "\n",
    "data = Data(edge_attr=edge_attr, edge_index=edge_index, edge_type=edge_type, x=x, y=y, train_mask=train_mask, val_mask=val_mask, test_mask=test_mask)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_type_mapping = {\n",
    "    0: 'target', \n",
    "    1: 'enzyme', \n",
    "    2: 'carrier', \n",
    "    3: 'transporter', \n",
    "    4: 'ppi', \n",
    "    5: 'target_rev',\n",
    "    6: 'enzyme_rev',\n",
    "    7: 'carrier_rev',\n",
    "    8: 'transporter_rev'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have 9 different edge types. The last 4 edge types are the opposites of the first 4 edge types as we want our graph to be un-directional.\n",
    "e.g. Drug A **targets** Protein A is equivalent to Protein A is **targeted** by Drug A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = GraphSAINTRandomWalkSampler(data, batch_size=128, walk_length=16, num_steps=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We utilize [GraphSAINT Random Walk Sampler](https://arxiv.org/pdf/1907.04931.pdf) as it allows us to sample fully-connected sub-graphs for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCN(torch.nn.Module):\n",
    "    def __init__(self, in_dim, h_dim, out_dim, num_rels):\n",
    "        super(RGCN, self).__init__()\n",
    "        self.num_rels = num_rels\n",
    "        self.conv1 = FastRGCNConv(\n",
    "            in_dim, h_dim, num_rels)\n",
    "        self.conv2 = FastRGCNConv(\n",
    "            h_dim, out_dim, num_rels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.w_rels = nn.Parameter(torch.Tensor(num_rels, out_dim))\n",
    "        nn.init.xavier_uniform_(self.w_rels,\n",
    "                                gain=nn.init.calculate_gain('relu'))\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_type):\n",
    "        x1 = self.conv1(x, edge_index, edge_type)\n",
    "        x1 = self.relu(x1)\n",
    "        x2 = self.conv2(x1, edge_index, edge_type)\n",
    "        out = F.log_softmax(x2, dim=1)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "def get_metrics(model, embed, edge_index, edge_type, labels):\n",
    "    probs = DistMult(embed, edge_index, edge_type, model)\n",
    "    loss = F.binary_cross_entropy(probs, labels)\n",
    "\n",
    "    probs = probs.cpu().detach().numpy()\n",
    "    labels = labels.cpu().detach().numpy()\n",
    "\n",
    "    return loss, probs, labels\n",
    "\n",
    "def DistMult(embed, edge_index, edge_type, model):\n",
    "    s = embed[edge_index[0, :]]\n",
    "    o = embed[edge_index[1, :]]\n",
    "    r = model.w_rels[edge_type]\n",
    "    scores = torch.sum(s * r * o, dim=1)\n",
    "    \n",
    "    return torch.sigmoid(scores)\n",
    "\n",
    "\n",
    "def get_link_labels(edge_index_pos_len, edge_index_neg_len):\n",
    "    link_labels = torch.zeros(edge_index_pos_len + edge_index_neg_len).float().to(device)\n",
    "    link_labels[:int(edge_index_pos_len)] = 1.\n",
    "    return link_labels\n",
    "\n",
    "def get_embeddings(data):\n",
    "    data = data.to(device)\n",
    "    x = data.x\n",
    "    edge_index_pos = data.edge_index\n",
    "    edge_type = torch.squeeze(data.edge_type)\n",
    "    embed = model(x, edge_index_pos, edge_type)\n",
    "    \n",
    "    return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'in_dim': 128, \n",
    "          'h_dim':64,\n",
    "          'out_dim':64,\n",
    "          'num_rels': num_relations,\n",
    "          'epochs':10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = RGCN(params['in_dim'], params['h_dim'], params['out_dim'], params['num_rels']).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we construct a 2-layer RGCN with hidden dimension of 64 for both node and edge embeddings. We model it as a binary classification task that tries to minimize the loss between real edge labels and fake edge labels geneated from negative sampling. We use RGCN as the encoder for node embeddings and DistMult as the decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "Note: the data for training is sampled from GraphSaint, whereas the data for validation is the whole graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, embed):\n",
    "    data = data.to(device)\n",
    "    x = data.x\n",
    "    \n",
    "    edge_index_train_pos = data.edge_index[:, data.train_mask]\n",
    "    edge_type_train = torch.squeeze(data.edge_type[data.train_mask])\n",
    "    \n",
    "    edge_index_train_neg = negative_sampling(edge_index_train_pos, num_neg_samples=edge_index_train_pos.size(1))\n",
    "\n",
    "    edge_index_train_total = torch.cat([edge_index_train_pos, edge_index_train_neg], dim=-1)\n",
    "    edge_type_train_total = torch.cat([edge_type_train, edge_type_train[:edge_index_train_neg.size(1)]], dim=-1)\n",
    "\n",
    "\n",
    "    link_labels = get_link_labels(edge_index_train_pos.size(1), edge_index_train_neg.size(1))\n",
    "    loss, probs, labels = get_metrics(model, embed, edge_index_train_total, edge_type_train_total, \n",
    "                                            link_labels)\n",
    "    \n",
    "    auroc = roc_auc_score(labels, probs)\n",
    "    auprc = average_precision_score(labels, probs)\n",
    "    \n",
    "    loss_epoch_train.append(loss.item())\n",
    "    auroc_epoch_train.append(auroc)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "@torch.no_grad()\n",
    "def validation(data, embed, evaluate_rel=False):\n",
    "    data = data.to(device)\n",
    "    x = data.x\n",
    "    \n",
    "    edge_index_val_pos = data.edge_index[:, data.val_mask]\n",
    "    edge_type_val = torch.squeeze(data.edge_type[data.val_mask])\n",
    "    \n",
    "    edge_index_val_neg = negative_sampling(edge_index_val_pos, num_neg_samples=edge_index_val_pos.size(1))\n",
    "    edge_index_val_total = torch.cat([edge_index_val_pos, edge_index_val_neg], dim=-1)\n",
    "    edge_type_val_total = torch.cat([edge_type_val, edge_type_val[:edge_index_val_neg.size(1)]], dim=-1)\n",
    "    \n",
    "    link_labels = get_link_labels(edge_index_val_pos.size(1), edge_index_val_neg.size(1))\n",
    "    loss, probs, labels = get_metrics(model, embed, edge_index_val_total, edge_type_val_total, \n",
    "                                                                link_labels)\n",
    "    auroc = roc_auc_score(labels, probs)\n",
    "    auprc = average_precision_score(labels, probs)\n",
    "    \n",
    "    edge_type_val_total = edge_type_val_total.detach().cpu()\n",
    "    \n",
    "    loss_epoch_val.append(loss.item())\n",
    "    auroc_epoch_val.append(auroc)\n",
    "    \n",
    "    if not evaluate_rel:\n",
    "        return\n",
    "    \n",
    "    for i in range(num_relations):\n",
    "        mask = (edge_type_val_total == i)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        probs_per_rel = probs[mask]\n",
    "        labels_per_rel = labels[mask]\n",
    "        auroc_per_rel = roc_auc_score(labels_per_rel, probs_per_rel)\n",
    "        auroc_edge_type[i].append(auroc_per_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1587428207430/work/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train loss: 23.41 | train auroc: 0.35 |\n",
      "Epoch: 1 | val loss: 23.20 | val auroc: 0.35 |\n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch: 2 | train loss: 4.42 | train auroc: 0.71 |\n",
      "Epoch: 2 | val loss: 4.34 | val auroc: 0.70 |\n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch: 3 | train loss: 0.79 | train auroc: 0.79 |\n",
      "Epoch: 3 | val loss: 0.80 | val auroc: 0.79 |\n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch: 4 | train loss: 0.66 | train auroc: 0.80 |\n",
      "Epoch: 4 | val loss: 0.66 | val auroc: 0.79 |\n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch: 5 | train loss: 0.62 | train auroc: 0.81 |\n",
      "Epoch: 5 | val loss: 0.62 | val auroc: 0.80 |\n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch: 6 | train loss: 0.59 | train auroc: 0.81 |\n",
      "Epoch: 6 | val loss: 0.60 | val auroc: 0.81 |\n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch: 7 | train loss: 0.56 | train auroc: 0.82 |\n",
      "Epoch: 7 | val loss: 0.56 | val auroc: 0.82 |\n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch: 8 | train loss: 0.53 | train auroc: 0.83 |\n",
      "Epoch: 8 | val loss: 0.53 | val auroc: 0.82 |\n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch: 9 | train loss: 0.52 | train auroc: 0.83 |\n",
      "Epoch: 9 | val loss: 0.52 | val auroc: 0.83 |\n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch: 10 | train loss: 0.50 | train auroc: 0.84 |\n",
      "Epoch: 10 | val loss: 0.51 | val auroc: 0.84 |\n",
      "----------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "loss_train_total, loss_val_total = [], []\n",
    "auroc_train_total, auroc_val_total = [], []\n",
    "\n",
    "for epoch in range(0, params['epochs']):\n",
    "    loss_epoch_train, loss_epoch_val = [], []\n",
    "    auroc_epoch_train, auroc_epoch_val = [], []\n",
    "\n",
    "    for batch in data_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "        embed = get_embeddings(batch)\n",
    "        train(batch, embed)\n",
    "        model.eval()\n",
    "        validation(batch, embed)\n",
    "    \n",
    "    loss_train_total.append(np.mean(loss_epoch_train))\n",
    "    auroc_train_total.append(np.mean(auroc_epoch_train))\n",
    "    loss_val_total.append(np.mean(loss_epoch_val))\n",
    "    auroc_val_total.append(np.mean(auroc_epoch_val))\n",
    "\n",
    "    print('Epoch: {} | train loss: {} | train auroc: {} |'.format(epoch + 1, \n",
    "                                                                  \"%.2f\" % np.mean(loss_epoch_train), \n",
    "                                                                  \"%.2f\" % np.mean(auroc_epoch_train)))\n",
    "    print('Epoch: {} | val loss: {} | val auroc: {} |'.format(epoch + 1, \n",
    "                                                              \"%.2f\" % np.mean(loss_epoch_val), \n",
    "                                                              \"%.2f\" % np.mean(auroc_epoch_val)))\n",
    "    \n",
    "    print('----------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auroc for relation type target: 0.987\n",
      "auroc for relation type enzyme: 0.997\n",
      "auroc for relation type carrier: 0.983\n",
      "auroc for relation type transporter: 0.987\n",
      "auroc for relation type ppi: 0.837\n",
      "auroc for relation type target_rev: 0.991\n",
      "auroc for relation type enzyme_rev: 0.997\n",
      "auroc for relation type carrier_rev: 1.000\n",
      "auroc for relation type transporter_rev: 0.991\n"
     ]
    }
   ],
   "source": [
    "auroc_edge_type = {rel:[] for rel in range(num_relations)}\n",
    "\n",
    "for batch in data_loader:\n",
    "    embed = get_embeddings(batch)\n",
    "    validation(batch, embed, evaluate_rel=True)\n",
    "\n",
    "for rel, values in auroc_edge_type.items():\n",
    "     print('auroc for relation type {}: {}'.format(edge_type_mapping[rel], \"%.3f\" % np.mean(values)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
